{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"c4cd63a4c6c645e5809fb9d305fa83e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7dfdacd8ec74f09adcfa82f453505ca","IPY_MODEL_5f530b063bc541f3a2400df68ec75c7b","IPY_MODEL_d49f0d636d454181aa53c0ec17285ed9"],"layout":"IPY_MODEL_8ce6d2640d4f42eb80a0b23de6d53d79"}},"d7dfdacd8ec74f09adcfa82f453505ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eced711706f04e90a4a3a3e232f21df5","placeholder":"​","style":"IPY_MODEL_1fe429f6435f4032a9d0a0bab695f700","value":"Downloading pytorch_model.bin: 100%"}},"5f530b063bc541f3a2400df68ec75c7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_deb5c7e2f2524d1cb65ff0520a5b608d","max":495536138,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dca8ae4807834948989779f96a489604","value":495536138}},"d49f0d636d454181aa53c0ec17285ed9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec64182d680a44c7bf3c9fb260b6d702","placeholder":"​","style":"IPY_MODEL_7622aee221ac4d14aa56589cdb87e097","value":" 496M/496M [00:22&lt;00:00, 22.9MB/s]"}},"8ce6d2640d4f42eb80a0b23de6d53d79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eced711706f04e90a4a3a3e232f21df5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fe429f6435f4032a9d0a0bab695f700":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"deb5c7e2f2524d1cb65ff0520a5b608d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dca8ae4807834948989779f96a489604":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec64182d680a44c7bf3c9fb260b6d702":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7622aee221ac4d14aa56589cdb87e097":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# SmileGate Style Dataset을 이용한 텍스트 스타일 변경 모델\n","\n","- https://github.com/smilegate-ai/korean_smile_style_dataset\n","\n","## References\n","- https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/pipelines#transformers.Text2TextGenerationPipeline\n","- https://huggingface.co/docs/transformers/v4.20.1/en/model_doc/bart#transformers.BartForConditionalGeneration\n","- https://huggingface.co/docs/transformers/tasks/summarization\n","- https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.early_stopping\n","- https://huggingface.co/docs/transformers/internal/generation_utils\n"],"metadata":{"id":"F8QQRfEocJfC"}},{"cell_type":"code","source":["!pip install transformers\n","!wget https://raw.githubusercontent.com/smilegate-ai/korean_smile_style_dataset/main/smilestyle_dataset.tsv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92Z8dt3ZcgvE","outputId":"f8e31946-f868-459f-aa7d-c873b21595a8","executionInfo":{"status":"ok","timestamp":1678864455345,"user_tz":-540,"elapsed":5529,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n","--2023-03-15 07:14:14--  https://raw.githubusercontent.com/smilegate-ai/korean_smile_style_dataset/main/smilestyle_dataset.tsv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2357401 (2.2M) [text/plain]\n","Saving to: ‘smilestyle_dataset.tsv.1’\n","\n","smilestyle_dataset. 100%[===================>]   2.25M  --.-KB/s    in 0.08s   \n","\n","2023-03-15 07:14:14 (29.5 MB/s) - ‘smilestyle_dataset.tsv.1’ saved [2357401/2357401]\n","\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"5VwMLau1liYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uB2FzhiscCwP"},"outputs":[],"source":["\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq,\n",")\n","from tokenizers import Tokenizer\n","from typing import Dict, List, Optional\n","from torch.utils.data import Dataset\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","from IPython.display import display\n","from typing import Dict"]},{"cell_type":"code","source":["df = pd.read_csv(\"smilestyle_dataset.tsv\", sep=\"\\t\")\n","display(df.head())\n","display(df.isna().mean())\n","display(df.describe())\n","print(df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"edoiJ-Kxcafx","outputId":"56d86a60-818b-4eeb-aedc-3eb91d116137","executionInfo":{"status":"ok","timestamp":1678864338614,"user_tz":-540,"elapsed":869,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                        formal                    informal  \\\n","0       안녕하세요. 저는 고양이 6마리 키워요.          안녕! 나는 고양이 6마리 키워.   \n","1     고양이를 6마리나요? 키우는거 안 힘드세요?      고양이를 6마리나? 키우는거 안 힘들어?   \n","2  제가 워낙 고양이를 좋아해서 크게 힘들진 않아요.  내가 워낙 고양이를 좋아해서 크게 힘들진 않아.   \n","3       가장 나이가 많은 고양이가 어떻게 돼요?       가장 나이가 많은 고양이가 몇 살이야?   \n","4           여섯 살입니다. 갈색 고양이에요.            여섯 살이야. 갈색 고양이지.   \n","\n","                           android                                   azae  \\\n","0  휴먼. 반갑다. 안드로이드는. 고양이. 6마리. 소유중.  아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여   \n","1             고양이. 6마리. 양육. 번거로운가.        아니 무슨 고양이를 6마리나? 거 키우는 거 안 힘든가?   \n","2         안드로이드. 고양이. 선호. 힘들지. 않음.        내가 또 워~낙에 고양이를 좋아해서 크게 뭐 힘들진 않고   \n","3           제일. 나이많은. 고양이. 나이. 무엇.                그려 가장 나이가 많은 고양이가 몇살이여?   \n","4                    고양이. 갈색. 여섯살.                        6살인데 갈색 고양이 있어~   \n","\n","                     chat                 choding  \\\n","0     하잉ㅋㅋ 나 떼걸룩 6마리 키운다!      ㅎㅇ 나 주인님 6마리 모심 ㅋㅋ   \n","1       엥? 6마리나? 안힘듬?ㅋㅋㅋㅋ        6마리? 에바아니냐 안 힘듦?   \n","2  내가 고양이 좋아해서 딱히 안힘듬 ㅋㅋㅋ  ㄱㅊ 나 고양이 환장해서 힘든 것도 모름   \n","3     가장 나이 먹은 고양이가 몇살이야?         젤 낡은 고영희가 몇 살임?   \n","4        이제 여섯살이고 갈색고양이임!                 6살, 갈색임   \n","\n","                                  emoticon  \\\n","0        안녕!! >< 나는 고양이😺를 ➏ 마리 키우고있어!! 0_0   \n","1  고양이를 6마리나?!! w(ﾟДﾟ)w 키우는거 안 힘듬?? (⊙_⊙;)   \n","2    뭐 나야 워낙에 고양이 좋아하니까 딱히 안힘드엉! \\(@^0^@)/   \n","3             가장 나이 먹은 고양인 몇 살이양? (´･ω･`)?   \n","4           여설 살!! ㄱ^o^/ 색깔은 갈색! O(*￣▽￣*)ブ   \n","\n","                                       enfp                        gentle  \\\n","0           안녕안녕~! 나 고양이 6마리나 키운다? 완전 대박이징~     안녕하십니까,, 저는 고양이 6마리 키웁니다.   \n","1           고양이를 6마리나? 완전 대박~ 키우는 거 안 힘들어?!     고양이를 6마리나 키우십니까? 안 힘드신지,,   \n","2  내가 또 워~낙에 고양이를 좋아하잖아~ 그렇게 크~게 힘들진 않아 ㅎㅎ~  제가 워낙 고양이를 좋아해서 크게 힘들진 않습니다.   \n","3    대박대박 완전 대박!! 그럼 제~일 나이 많은 고양이는 몇살이야~?!         가장 나이가 있는 고양이가 몇살입니까?   \n","4     6살인 애 있는데, 완전 귀.여.워. 갈색 고양이야 진짜 대박이지?              6살된 갈색 아이가 있습니다.   \n","\n","                                halbae                       halmae  \\\n","0      안녕하신가~... 난 지금 고양이를 6마리 키우고 있다네  하유 시벌것 괭이놈 6마리 키우는데 힘들어 죽겟네   \n","1             고양이를 6마리나? 키우는거 힘들지 않는가?      니기럴 털만 날리는 거 키우기 안 힘들데?   \n","2  내가 워낙에...고양이가 좋아가지고 그렇게 힘들지 않어...^^         옘병 내가 좋아하니까 키워야지 시벌것   \n","3        고양이들 중에서…가장 나이 먹을 애가 몇살인가?...     거 젤 빨리 뒤질 놈이 나이 얼마나 쳐먹었냐   \n","4                  저…갈색 고양이인데…여섯살이지~..   저 노망난 갈색놈이 6살 뒤룩뒤룩 쳐먹은 놈이여   \n","\n","                   joongding                         king  \\\n","0  안녕하냐 ㅡㅡ 나 씹냥이 6마리나 키운다 하;       반갑소. 짐은 고양이를 6마리나 키우오.   \n","1        아니 고양이를 6마리나? 안힘드냐?    고양이를 6마리나? 키우는게 수고스럽진 않소?   \n","2      고양이 좋아한다고ㅡㅡ 1도 안힘듬 ㅡㅡ  과인은 고양이를 어여삐 어겨 그리 수고스럽진 않소   \n","3               가장 늙은애가 몇살인데        최고령 고양이의 나이는 어떻게 되는가?   \n","4                여섯살 갈색냥인데 왜             여섯 살이오. 갈색 고양이오.   \n","\n","                         naruto                            seonbi  \\\n","0   안녕하냐니깐! 난 고양이를 6마리 키우고있다니깐!       안녕하시오! 소인은 고양이를 6마리 키우고 있소!   \n","1     고양이를 6마리나? 키우는거 힘들지 않냐니깐?     고양이를 6마리나 키우고 있는 것이오? 힘들지 않소?   \n","2  내가 고양이를 엄청 좋아해서 별로 힘들지 않다니깐!  소인 고양이를 엄청 좋아하기 때문에 별로 힘들지 않소이다.   \n","3   가장 나이 많이 먹은 고양이가 몇 살 이냐니깐?!          나이를 가장 많이 먹은 고양이가 몇 살이오?   \n","4              갈색 고양이가 여섯살이라니깐!                     여섯 살에 갈색 고양이오   \n","\n","                                 sosim                     translator  \n","0                  안녕… 난 고양이 6마리 키워 ㅠㅠ     반가운. 나는 6마리의 고양이를 소지하고 있다.  \n","1         고양이..6마리나? ㅠ 키우는건 혹시 안힘들어..?  6마리의 고양이? 당신은 그들로부터 지치지 않습니까?  \n","2  내가 고양이 워낙 좋아해서..ㅠㅠ 크게 힘들진 않은 것 같아..        나는 고양이의 큰 애호가. 지치지 않는다.  \n","3        혹시.. 제일 나이 많은 고양이는.. 몇살이야..?ㅠ             가장 늙은 고양이가 몇 년입니까?  \n","4                여섯살이야.. 갈색 ㅠㅠ 고양이야..ㅠ                 여섯. 고양이는 갈색이다.  "],"text/html":["\n","  <div id=\"df-142c25c2-cbf2-4886-899e-e6bd3e7e149f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>formal</th>\n","      <th>informal</th>\n","      <th>android</th>\n","      <th>azae</th>\n","      <th>chat</th>\n","      <th>choding</th>\n","      <th>emoticon</th>\n","      <th>enfp</th>\n","      <th>gentle</th>\n","      <th>halbae</th>\n","      <th>halmae</th>\n","      <th>joongding</th>\n","      <th>king</th>\n","      <th>naruto</th>\n","      <th>seonbi</th>\n","      <th>sosim</th>\n","      <th>translator</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>안녕하세요. 저는 고양이 6마리 키워요.</td>\n","      <td>안녕! 나는 고양이 6마리 키워.</td>\n","      <td>휴먼. 반갑다. 안드로이드는. 고양이. 6마리. 소유중.</td>\n","      <td>아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여</td>\n","      <td>하잉ㅋㅋ 나 떼걸룩 6마리 키운다!</td>\n","      <td>ㅎㅇ 나 주인님 6마리 모심 ㅋㅋ</td>\n","      <td>안녕!! &gt;&lt; 나는 고양이😺를 ➏ 마리 키우고있어!! 0_0</td>\n","      <td>안녕안녕~! 나 고양이 6마리나 키운다? 완전 대박이징~</td>\n","      <td>안녕하십니까,, 저는 고양이 6마리 키웁니다.</td>\n","      <td>안녕하신가~... 난 지금 고양이를 6마리 키우고 있다네</td>\n","      <td>하유 시벌것 괭이놈 6마리 키우는데 힘들어 죽겟네</td>\n","      <td>안녕하냐 ㅡㅡ 나 씹냥이 6마리나 키운다 하;</td>\n","      <td>반갑소. 짐은 고양이를 6마리나 키우오.</td>\n","      <td>안녕하냐니깐! 난 고양이를 6마리 키우고있다니깐!</td>\n","      <td>안녕하시오! 소인은 고양이를 6마리 키우고 있소!</td>\n","      <td>안녕… 난 고양이 6마리 키워 ㅠㅠ</td>\n","      <td>반가운. 나는 6마리의 고양이를 소지하고 있다.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>고양이를 6마리나요? 키우는거 안 힘드세요?</td>\n","      <td>고양이를 6마리나? 키우는거 안 힘들어?</td>\n","      <td>고양이. 6마리. 양육. 번거로운가.</td>\n","      <td>아니 무슨 고양이를 6마리나? 거 키우는 거 안 힘든가?</td>\n","      <td>엥? 6마리나? 안힘듬?ㅋㅋㅋㅋ</td>\n","      <td>6마리? 에바아니냐 안 힘듦?</td>\n","      <td>고양이를 6마리나?!! w(ﾟДﾟ)w 키우는거 안 힘듬?? (⊙_⊙;)</td>\n","      <td>고양이를 6마리나? 완전 대박~ 키우는 거 안 힘들어?!</td>\n","      <td>고양이를 6마리나 키우십니까? 안 힘드신지,,</td>\n","      <td>고양이를 6마리나? 키우는거 힘들지 않는가?</td>\n","      <td>니기럴 털만 날리는 거 키우기 안 힘들데?</td>\n","      <td>아니 고양이를 6마리나? 안힘드냐?</td>\n","      <td>고양이를 6마리나? 키우는게 수고스럽진 않소?</td>\n","      <td>고양이를 6마리나? 키우는거 힘들지 않냐니깐?</td>\n","      <td>고양이를 6마리나 키우고 있는 것이오? 힘들지 않소?</td>\n","      <td>고양이..6마리나? ㅠ 키우는건 혹시 안힘들어..?</td>\n","      <td>6마리의 고양이? 당신은 그들로부터 지치지 않습니까?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>제가 워낙 고양이를 좋아해서 크게 힘들진 않아요.</td>\n","      <td>내가 워낙 고양이를 좋아해서 크게 힘들진 않아.</td>\n","      <td>안드로이드. 고양이. 선호. 힘들지. 않음.</td>\n","      <td>내가 또 워~낙에 고양이를 좋아해서 크게 뭐 힘들진 않고</td>\n","      <td>내가 고양이 좋아해서 딱히 안힘듬 ㅋㅋㅋ</td>\n","      <td>ㄱㅊ 나 고양이 환장해서 힘든 것도 모름</td>\n","      <td>뭐 나야 워낙에 고양이 좋아하니까 딱히 안힘드엉! \\(@^0^@)/</td>\n","      <td>내가 또 워~낙에 고양이를 좋아하잖아~ 그렇게 크~게 힘들진 않아 ㅎㅎ~</td>\n","      <td>제가 워낙 고양이를 좋아해서 크게 힘들진 않습니다.</td>\n","      <td>내가 워낙에...고양이가 좋아가지고 그렇게 힘들지 않어...^^</td>\n","      <td>옘병 내가 좋아하니까 키워야지 시벌것</td>\n","      <td>고양이 좋아한다고ㅡㅡ 1도 안힘듬 ㅡㅡ</td>\n","      <td>과인은 고양이를 어여삐 어겨 그리 수고스럽진 않소</td>\n","      <td>내가 고양이를 엄청 좋아해서 별로 힘들지 않다니깐!</td>\n","      <td>소인 고양이를 엄청 좋아하기 때문에 별로 힘들지 않소이다.</td>\n","      <td>내가 고양이 워낙 좋아해서..ㅠㅠ 크게 힘들진 않은 것 같아..</td>\n","      <td>나는 고양이의 큰 애호가. 지치지 않는다.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>가장 나이가 많은 고양이가 어떻게 돼요?</td>\n","      <td>가장 나이가 많은 고양이가 몇 살이야?</td>\n","      <td>제일. 나이많은. 고양이. 나이. 무엇.</td>\n","      <td>그려 가장 나이가 많은 고양이가 몇살이여?</td>\n","      <td>가장 나이 먹은 고양이가 몇살이야?</td>\n","      <td>젤 낡은 고영희가 몇 살임?</td>\n","      <td>가장 나이 먹은 고양인 몇 살이양? (´･ω･`)?</td>\n","      <td>대박대박 완전 대박!! 그럼 제~일 나이 많은 고양이는 몇살이야~?!</td>\n","      <td>가장 나이가 있는 고양이가 몇살입니까?</td>\n","      <td>고양이들 중에서…가장 나이 먹을 애가 몇살인가?...</td>\n","      <td>거 젤 빨리 뒤질 놈이 나이 얼마나 쳐먹었냐</td>\n","      <td>가장 늙은애가 몇살인데</td>\n","      <td>최고령 고양이의 나이는 어떻게 되는가?</td>\n","      <td>가장 나이 많이 먹은 고양이가 몇 살 이냐니깐?!</td>\n","      <td>나이를 가장 많이 먹은 고양이가 몇 살이오?</td>\n","      <td>혹시.. 제일 나이 많은 고양이는.. 몇살이야..?ㅠ</td>\n","      <td>가장 늙은 고양이가 몇 년입니까?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>여섯 살입니다. 갈색 고양이에요.</td>\n","      <td>여섯 살이야. 갈색 고양이지.</td>\n","      <td>고양이. 갈색. 여섯살.</td>\n","      <td>6살인데 갈색 고양이 있어~</td>\n","      <td>이제 여섯살이고 갈색고양이임!</td>\n","      <td>6살, 갈색임</td>\n","      <td>여설 살!! ㄱ^o^/ 색깔은 갈색! O(*￣▽￣*)ブ</td>\n","      <td>6살인 애 있는데, 완전 귀.여.워. 갈색 고양이야 진짜 대박이지?</td>\n","      <td>6살된 갈색 아이가 있습니다.</td>\n","      <td>저…갈색 고양이인데…여섯살이지~..</td>\n","      <td>저 노망난 갈색놈이 6살 뒤룩뒤룩 쳐먹은 놈이여</td>\n","      <td>여섯살 갈색냥인데 왜</td>\n","      <td>여섯 살이오. 갈색 고양이오.</td>\n","      <td>갈색 고양이가 여섯살이라니깐!</td>\n","      <td>여섯 살에 갈색 고양이오</td>\n","      <td>여섯살이야.. 갈색 ㅠㅠ 고양이야..ㅠ</td>\n","      <td>여섯. 고양이는 갈색이다.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-142c25c2-cbf2-4886-899e-e6bd3e7e149f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-142c25c2-cbf2-4886-899e-e6bd3e7e149f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-142c25c2-cbf2-4886-899e-e6bd3e7e149f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["formal        0.063428\n","informal      0.063428\n","android       0.520918\n","azae          0.723347\n","chat          0.063428\n","choding       0.063428\n","emoticon      0.514980\n","enfp          0.544130\n","gentle        0.540351\n","halbae        0.515789\n","halmae        0.726586\n","joongding     0.063428\n","king          0.520918\n","naruto        0.514980\n","seonbi        0.514980\n","sosim         0.520918\n","translator    0.594062\n","dtype: float64"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["        formal informal android                                   azae  chat  \\\n","count     3470     3470    1775                                   1025  3470   \n","unique    3430     3417    1748                                   1025  3437   \n","top     안녕하세요.      안녕.    반갑다.  아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여    하이   \n","freq        23       25      10                                      1    13   \n","\n","       choding      emoticon  enfp  gentle  halbae halmae joongding  king  \\\n","count     3470          1797  1689    1703    1794   1013      3470  1775   \n","unique    3390          1793  1679    1691    1784   1005      3396  1759   \n","top         왜?  안녕! (ﾉ*･ω･)ﾉ   안뇽~  안녕하십니까  안녕하신가…  왜 땜시?        ㅎㅇ  반갑소.   \n","freq        37             3     6       5       8      4        29     7   \n","\n","         naruto  seonbi sosim translator  \n","count      1797    1797  1775       1504  \n","unique     1779    1784  1758       1489  \n","top     안녕하냐니깐!  안녕하시오!  안녕..       반가운.  \n","freq          9       9     9          9  "],"text/html":["\n","  <div id=\"df-d237a8f2-5360-4b40-af6d-0211bb6118c1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>formal</th>\n","      <th>informal</th>\n","      <th>android</th>\n","      <th>azae</th>\n","      <th>chat</th>\n","      <th>choding</th>\n","      <th>emoticon</th>\n","      <th>enfp</th>\n","      <th>gentle</th>\n","      <th>halbae</th>\n","      <th>halmae</th>\n","      <th>joongding</th>\n","      <th>king</th>\n","      <th>naruto</th>\n","      <th>seonbi</th>\n","      <th>sosim</th>\n","      <th>translator</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3470</td>\n","      <td>3470</td>\n","      <td>1775</td>\n","      <td>1025</td>\n","      <td>3470</td>\n","      <td>3470</td>\n","      <td>1797</td>\n","      <td>1689</td>\n","      <td>1703</td>\n","      <td>1794</td>\n","      <td>1013</td>\n","      <td>3470</td>\n","      <td>1775</td>\n","      <td>1797</td>\n","      <td>1797</td>\n","      <td>1775</td>\n","      <td>1504</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>3430</td>\n","      <td>3417</td>\n","      <td>1748</td>\n","      <td>1025</td>\n","      <td>3437</td>\n","      <td>3390</td>\n","      <td>1793</td>\n","      <td>1679</td>\n","      <td>1691</td>\n","      <td>1784</td>\n","      <td>1005</td>\n","      <td>3396</td>\n","      <td>1759</td>\n","      <td>1779</td>\n","      <td>1784</td>\n","      <td>1758</td>\n","      <td>1489</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>안녕하세요.</td>\n","      <td>안녕.</td>\n","      <td>반갑다.</td>\n","      <td>아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여</td>\n","      <td>하이</td>\n","      <td>왜?</td>\n","      <td>안녕! (ﾉ*･ω･)ﾉ</td>\n","      <td>안뇽~</td>\n","      <td>안녕하십니까</td>\n","      <td>안녕하신가…</td>\n","      <td>왜 땜시?</td>\n","      <td>ㅎㅇ</td>\n","      <td>반갑소.</td>\n","      <td>안녕하냐니깐!</td>\n","      <td>안녕하시오!</td>\n","      <td>안녕..</td>\n","      <td>반가운.</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>23</td>\n","      <td>25</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>13</td>\n","      <td>37</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>29</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d237a8f2-5360-4b40-af6d-0211bb6118c1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d237a8f2-5360-4b40-af6d-0211bb6118c1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d237a8f2-5360-4b40-af6d-0211bb6118c1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(3705, 17)\n"]}]},{"cell_type":"markdown","source":["특정 문장을 다른 스타일의 문장으로 바꾸기 위해선, 한 row가 2개 이상의 NaN이 아닌 값이 있어야 한다. \n","\n","확인결과 5개의 행이 그냥 빈 행이여서 전부 NaN인데 이 값들을 제거해준다. 3475행이 3470행으로 바뀌었다."],"metadata":{"id":"DORDxbkJjxvj"}},{"cell_type":"code","source":["row_notna_count = df.notna().sum(axis=1)\n","row_notna_count.plot.hist(bins=row_notna_count.max())\n","plt.show()\n","\n","df = df[row_notna_count >= 2]\n","print(len(df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"LuHj3IJPjrAZ","outputId":"bf2fe2c2-5e43-4491-98e4-2246d5d81926","executionInfo":{"status":"ok","timestamp":1678864340537,"user_tz":-540,"elapsed":5,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZAAAAD4CAYAAADCb7BPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXY0lEQVR4nO3de7SddX3n8fdHInip5ZaINAkN2hQHrY7pEelYHZQWuVhiO9bCeEmVacYRWh07o1G7xGWXa+F0KpXWMo2SERzLRbyQGeJgRKtr1iqXQJGrmiOCJAYSBUGrFdHv/LF/0c3hnGTn4ey9zzHv11p77ef5Pb/n2V+fPJ4Pzz1VhSRJe+ox4y5AkjQ/GSCSpE4MEElSJwaIJKkTA0SS1MmCcRcwDAsXLqxly5aNuwxJmleuu+66b1XVokH7/1wGyLJly9i0adO4y5CkeSXJnXvS30NYkqRODBBJUicGiCSpEwNEktSJASJJ6sQAkSR1YoBIkjoxQCRJnRggkqROhnYnepJ1wEuB7VX1zL72PwZOB34MXF5Vb2ntbwNOa+1/UlVXtPbjgfcD+wAfqqqzhlWzRmfZmstnZTl3nHXSrCxH0p4b5qNMPgz8DXDBzoYkLwJWAs+uqh8meXJrPxI4BXgG8EvAZ5P8apvtA8BvA1uAa5Osr6pbh1i3JGkAQwuQqvpikmVTmv8TcFZV/bD12d7aVwIXtfavJ5kEjmrTJqvqdoAkF7W+Bogkjdmoz4H8KvCCJFcn+UKS57b2xcBdff22tLaZ2h8hyeokm5Js2rFjxxBKlyT1G3WALAAOAo4G/itwSZLMxoKram1VTVTVxKJFAz+NWJLU0agf574F+ERVFXBNkp8AC4GtwNK+fktaG7tolySN0aj3QD4FvAignSTfF/gWsB44Jcl+SQ4HlgPXANcCy5McnmRfeifa14+4ZknSNIZ5Ge+FwDHAwiRbgDOBdcC6JDcDDwKr2t7ILUkuoXdy/CHg9Kr6cVvOGcAV9C7jXVdVtwyrZknS4IZ5FdapM0x61Qz93wO8Z5r2DcCGWSxNkjQLvBNdktSJASJJ6sQAkSR1YoBIkjoxQCRJnRggkqRODBBJUicGiCSpEwNEktSJASJJ6sQAkSR1YoBIkjoxQCRJnRggkqRODBBJUicGiCSpk6EFSJJ1Sba3tw9OnfanSSrJwjaeJOckmUxyY5IVfX1XJdncPquGVa8kac8Mcw/kw8DxUxuTLAWOA77R13wCvfegLwdWA+e2vgfRexXu84CjgDOTHDjEmiVJAxpagFTVF4F7p5l0NvAWoPraVgIXVM9VwAFJDgVeAmysqnur6j5gI9OEkiRp9EZ6DiTJSmBrVX1pyqTFwF1941ta20ztkqQxWzCqH0ryBODt9A5fDWP5q+kd/uKwww4bxk9IkvqMcg/kacDhwJeS3AEsAa5P8hRgK7C0r++S1jZT+yNU1dqqmqiqiUWLFg2hfElSv5EFSFXdVFVPrqplVbWM3uGoFVV1N7AeeE27Guto4P6q2gZcARyX5MB28vy41iZJGrNhXsZ7IfCPwBFJtiQ5bRfdNwC3A5PAB4E3AFTVvcCfA9e2z7tbmyRpzIZ2DqSqTt3N9GV9wwWcPkO/dcC6WS1OkvSoeSe6JKkTA0SS1IkBIknqxACRJHVigEiSOjFAJEmdGCCSpE4MEElSJwaIJKkTA0SS1IkBIknqxACRJHVigEiSOjFAJEmdGCCSpE4MEElSJwaIJKmTYb7Sdl2S7Ulu7mv7iyRfTnJjkk8mOaBv2tuSTCb5SpKX9LUf39omk6wZVr2SpD0zzD2QDwPHT2nbCDyzqp4FfBV4G0CSI4FTgGe0ef42yT5J9gE+AJwAHAmc2vpKksZsaAFSVV8E7p3S9pmqeqiNXgUsacMrgYuq6odV9XVgEjiqfSar6vaqehC4qPWVJI3ZOM+BvA74dBteDNzVN21La5up/RGSrE6yKcmmHTt2DKFcSVK/sQRIkncADwEfna1lVtXaqpqoqolFixbN1mIlSTNYMOofTPKHwEuBY6uqWvNWYGlftyWtjV20S5LGaKR7IEmOB94CnFxV3++btB44Jcl+SQ4HlgPXANcCy5McnmRfeifa14+yZknS9Ia2B5LkQuAYYGGSLcCZ9K662g/YmATgqqp6fVXdkuQS4FZ6h7ZOr6oft+WcAVwB7AOsq6pbhlWzJGlwQwuQqjp1mubzdtH/PcB7pmnfAGyYxdIkSbPAO9ElSZ0YIJKkTgwQSVInBogkqRMDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTgwQSVInBogkqRMDRJLUiQEiSerEAJEkdTLQ+0CS/FpV3TTsYiRpb7VszeWzspw7zjppVpYziEH3QP42yTVJ3pBk/0FmSLIuyfYkN/e1HZRkY5LN7fvA1p4k5ySZTHJjkhV986xq/TcnWbVH/+skSUMzUIBU1QuAVwJLgeuS/H2S397NbB8Gjp/Stga4sqqWA1e2cYAT6L0HfTmwGjgXeoFD71W4zwOOAs7cGTqSpPEa+BxIVW0G/gx4K/BvgXOSfDnJ783Q/4vAvVOaVwLnt+HzgZf1tV9QPVcBByQ5FHgJsLGq7q2q+4CNPDKUJEljMFCAJHlWkrOB24AXA79TVf+qDZ+9B793SFVta8N3A4e04cXAXX39trS2mdolSWM20El04K+BDwFvr6of7Gysqm8m+bMuP1xVlaS6zDudJKvpHf7isMMOm63FSpJmMOghrJOAv98ZHkkek+QJAFX1kT34vXvaoSna9/bWvpXe+ZWdlrS2mdofoarWVtVEVU0sWrRoD0qSJHUxaIB8Fnh83/gTWtueWg/svJJqFXBZX/tr2tVYRwP3t0NdVwDHJTmwnTw/rrVJksZs0ENYj6uq7+0cqarv7dwDmUmSC4FjgIVJttC7muos4JIkpwF3Aq9o3TcAJwKTwPeB17bfuTfJnwPXtn7vrqqpJ+YlSWMwaID8c5IVVXU9QJJfB36wqxmq6tQZJh07Td8CTp9hOeuAdQPWKUkakUED5E3Ax5J8EwjwFOAPhlWUJGnuGyhAquraJE8HjmhNX6mqHw2vLEnSXDfoHgjAc4FlbZ4VSaiqC4ZSlSRpzhv0YYofAZ4G3AD8uDUXYIBI0l5q0D2QCeDIdrJbkqSB7wO5md6Jc0mSgMH3QBYCtya5BvjhzsaqOnkoVUmS5rxBA+RdwyxCkjT/DHoZ7xeS/DKwvKo+2+5C32e4pUmS5rJBH+f+R8ClwN+1psXAp4ZUkyRpHhj0JPrpwPOBB+CnL5d68rCKkiTNfYMGyA+r6sGdI0kW0LsPRJK0lxo0QL6Q5O3A49u70D8G/O/hlSVJmusGDZA1wA7gJuA/0nv8eqc3EUqSfj4MehXWT4APto8kSQM/C+vrTHPOo6qeOusVSZLmhT15FtZOjwN+Hzho9suRJM0XA50Dqapv9322VtVfASd1/dEk/znJLUluTnJhksclOTzJ1Ukmk1ycZN/Wd782PtmmL+v6u5Kk2TPojYQr+j4TSV7Pnr1LpH9Zi4E/ASaq6pn07mg/BXgvcHZV/QpwH3Bam+U04L7WfnbrJ0kas0FD4C/7hh8C7gBe8Sh/9/FJfgQ8AdgGvBj49236+fSev3UusJKfPYvrUuBvksRHy0vSeA16FdaLZusHq2prkv8OfAP4AfAZ4DrgO1X1UOu2hd7jUmjfd7V5H0pyP3Aw8K3+5SZZDawGOOyww2arXEnSDAa9CuvNu5peVe8b9AeTHEhvr+Jw4Dv0bko8ftD5d1HDWmAtwMTEhHsnkjRke3IV1nOB9W38d4BrgM0dfvO3gK9X1Q6AJJ+g95ytA5IsaHshS4Ctrf9WYCmwpT1CZX/g2x1+V5I0iwYNkCXAiqr6LkCSdwGXV9WrOvzmN4Cj2yPhfwAcC2wCPg+8HLgIWAVc1vqvb+P/2KZ/zvMfkjR+gz7K5BDgwb7xB1vbHquqq+mdDL+e3qNRHkPv0NNbgTcnmaR3juO8Nst5wMGt/c30HqsiSRqzQfdALgCuSfLJNv4yeldKdVJVZwJnTmm+HThqmr7/Qu/GRUnSHDLoVVjvSfJp4AWt6bVV9U/DK0uSNNcNeggLevdrPFBV76d3QvvwIdUkSZoHBr0T/Ux65yje1poeC/yvYRUlSZr7Bt0D+V3gZOCfAarqm8CThlWUJGnuGzRAHmyXzhZAkicOryRJ0nwwaIBckuTv6N3s90fAZ/HlUpK0V9vtVVhJAlwMPB14ADgCeGdVbRxybZKkOWy3AVJVlWRDVf0aYGhIkoDBD2Fdn+S5Q61EkjSvDHon+vOAVyW5g96VWKG3c/KsYRUmSZrbdhkgSQ6rqm8ALxlRPZKkeWJ3eyCfovcU3juTfLyq/t0IapIkzQO7OweSvuGnDrMQSdL8srsAqRmGJUl7ud0dwnp2kgfo7Yk8vg3Dz06i/+JQq5MkzVm7DJCq2mdUhUiS5pc9eZz7rElyQJJLk3w5yW1JfiPJQUk2Jtncvg9sfZPknCSTSW5MsmIcNUuSHm4sAQK8H/i/VfV04NnAbfReVXtlVS0HruRnr649AVjePquBc0dfriRpqpEHSJL9gRfS3nleVQ9W1XeAlfzsNbnn03ttLq39guq5it4DHQ8dadGSpEcYxx7I4cAO4H8m+ackH2qPhz+kqra1PncDh7ThxcBdffNvaW0Pk2R1kk1JNu3YsWOI5UuSYDwBsgBYAZxbVc+h92iUNf0d+t89MqiqWltVE1U1sWjRolkrVpI0vXEEyBZgS1Vd3cYvpRco9+w8NNW+t7fpW4GlffMvaW2SpDEaeYBU1d3AXUmOaE3HArcC64FVrW0VcFkbXg+8pl2NdTRwf9+hLknSmAz6NN7Z9sfAR5PsC9wOvJZemF2S5DTgTuAVre8G4ERgEvh+6ytJGrOxBEhV3QBMTDPp2Gn6FnD6sGuSJO2Zcd0HIkma5wwQSVInBogkqRMDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTgwQSVInBogkqRMDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTsb1SluS7ANsArZW1UuTHA5cBBwMXAe8uqoeTLIfcAHw68C3gT+oqjvGVLYkPcyyNZePu4SxGeceyBuB2/rG3wucXVW/AtwHnNbaTwPua+1nt36SpDEbS4AkWQKcBHyojQd4MXBp63I+8LI2vLKN06Yf2/pLksZoXHsgfwW8BfhJGz8Y+E5VPdTGtwCL2/Bi4C6ANv3+1v9hkqxOsinJph07dgyxdEkSjCFAkrwU2F5V183mcqtqbVVNVNXEokWLZnPRkqRpjOMk+vOBk5OcCDwO+EXg/cABSRa0vYwlwNbWfyuwFNiSZAGwP72T6ZKkMRr5HkhVva2qllTVMuAU4HNV9Urg88DLW7dVwGVteH0bp03/XFXVCEuWJE1jLt0H8lbgzUkm6Z3jOK+1nwcc3NrfDKwZU32SpD5juw8EoKr+AfiHNnw7cNQ0ff4F+P2RFiZJ2q25tAciSZpHDBBJUicGiCSpEwNEktSJASJJ6sQAkSR1YoBIkjoxQCRJnRggkqRODBBJUicGiCSpEwNEktSJASJJ6sQAkSR1YoBIkjoZ6/tA5qplay6fleXccdZJs7IcSZqLRr4HkmRpks8nuTXJLUne2NoPSrIxyeb2fWBrT5JzkkwmuTHJilHXLEl6pHEcwnoI+NOqOhI4Gjg9yZH0XlV7ZVUtB67kZ6+uPQFY3j6rgXNHX7IkaaqRB0hVbauq69vwd4HbgMXASuD81u184GVteCVwQfVcBRyQ5NDRVi1JmmqsJ9GTLAOeA1wNHFJV29qku4FD2vBi4K6+2ba0tqnLWp1kU5JNO3bsGF7RkiRgjAGS5BeAjwNvqqoH+qdVVQG1J8urqrVVNVFVE4sWLZrFSiVJ0xnLVVhJHksvPD5aVZ9ozfckObSqtrVDVNtb+1Zgad/sS1qbJHU2W1db7s3GcRVWgPOA26rqfX2T1gOr2vAq4LK+9te0q7GOBu7vO9QlSRqTceyBPB94NXBTkhta29uBs4BLkpwG3Am8ok3bAJwITALfB1470molSdMaeYBU1f8DMsPkY6fpX8DpQy1KkrTHfJSJJKkTA0SS1IkBIknqxACRJHVigEiSOjFAJEmdGCCSpE4MEElSJwaIJKkTX2kraWRm4wGGvip67nAPRJLUiXsg0hw0W48a97/WNUzugUiSOjFAJEmdeAhL0rzimwTnDvdAJEmdGCCSpE7mTYAkOT7JV5JMJlkz7nokaW83LwIkyT7AB4ATgCOBU5McOd6qJGnvNi8CBDgKmKyq26vqQeAiYOWYa5KkvVqqatw17FaSlwPHV9V/aOOvBp5XVWf09VkNrG6jRwBfeRQ/uRD41qOYf9TmW71gzaMy32qeb/XCz1fNv1xViwZdyM/NZbxVtRZYOxvLSrKpqiZmY1mjMN/qBWselflW83yrF/bumufLIaytwNK+8SWtTZI0JvMlQK4Flic5PMm+wCnA+jHXJEl7tXlxCKuqHkpyBnAFsA+wrqpuGeJPzsqhsBGab/WCNY/KfKt5vtULe3HN8+IkuiRp7pkvh7AkSXOMASJJ6mSvDZDdPRolyX5JLm7Tr06ybAxl9tezNMnnk9ya5JYkb5ymzzFJ7k9yQ/u8cxy1TqnpjiQ3tXo2TTM9Sc5p6/nGJCvGUWdfPUf0rb8bkjyQ5E1T+ox9PSdZl2R7kpv72g5KsjHJ5vZ94Azzrmp9NidZNcZ6/yLJl9u/+yeTHDDDvLvchkZc87uSbO37tz9xhnnH8uilGWq+uK/eO5LcMMO8e76eq2qv+9A7Ef814KnAvsCXgCOn9HkD8D/a8CnAxWOu+VBgRRt+EvDVaWo+Bvg/416/U2q6A1i4i+knAp8GAhwNXD3umqdsJ3fTu7lqTq1n4IXACuDmvrb/Bqxpw2uA904z30HA7e37wDZ84JjqPQ5Y0IbfO129g2xDI675XcB/GWC72eXfl1HWPGX6XwLvnK31vLfugQzyaJSVwPlt+FLg2CQZYY0PU1Xbqur6Nvxd4DZg8bjqmUUrgQuq5yrggCSHjruo5ljga1V157gLmaqqvgjcO6W5f5s9H3jZNLO+BNhYVfdW1X3ARuD4YdW503T1VtVnquqhNnoVvfu75owZ1vEgxvbopV3V3P5+vQK4cLZ+b28NkMXAXX3jW3jkH+Of9mkb+f3AwSOpbjfa4bTnAFdPM/k3knwpyaeTPGO0lU2rgM8kua49bmaqQf4txuUUZv4/21xbzwCHVNW2Nnw3cMg0febq+n4dvT3R6exuGxq1M9pht3UzHCacq+v4BcA9VbV5hul7vJ731gCZt5L8AvBx4E1V9cCUydfTO9zybOCvgU+NuLzp/GZVraD3JOXTk7xw3AUNot2wejLwsWkmz8X1/DDVOyYxL67RT/IO4CHgozN0mUvb0LnA04B/DWyjd0hovjiVXe997PF63lsDZJBHo/y0T5IFwP7At0dS3QySPJZeeHy0qj4xdXpVPVBV32vDG4DHJlk44jKn1rS1fW8HPklv977fXH1MzQnA9VV1z9QJc3E9N/fsPPzXvrdP02dOre8kfwi8FHhlC71HGGAbGpmquqeqflxVPwE+OEMtc2odw0//hv0ecPFMfbqs5701QAZ5NMp6YOcVKi8HPjfTBj4K7fjlecBtVfW+Gfo8Zed5miRH0fv3HVvoJXlikiftHKZ30vTmKd3WA69pV2MdDdzfdxhmnGb8r7W5tp779G+zq4DLpulzBXBckgPb4ZfjWtvIJTkeeAtwclV9f4Y+g2xDIzPl/NzvzlDLXHz00m8BX66qLdNN7LyeR3FlwFz80Lv656v0rpZ4R2t7N72NGeBx9A5fTALXAE8dc72/Se+QxI3ADe1zIvB64PWtzxnALfSu+rgK+DdjrvmprZYvtbp2ruf+mkPvZWFfA24CJubAtvFEeoGwf1/bnFrP9MJtG/AjesfYT6N3ju5KYDPwWeCg1ncC+FDfvK9r2/Uk8Nox1jtJ71zBzu1551WPvwRs2NU2NMaaP9K20xvphcKhU2tu44/4+zKumlv7h3duv319H/V69lEmkqRO9tZDWJKkR8kAkSR1YoBIkjoxQCRJnRggkqRODBBJUicGiCSpk/8PVRZhyex5gFoAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["3470\n"]}]},{"cell_type":"markdown","source":["# 텍스트를 토큰화했을 때 길이가 어느정도인지 확인해보기\n","\n","학습을 위해서는 특정 길이로 자른 뒤 padding 처리를 해주어야하는데, 그러기 위해선 학습 데이터들의 길이가 어느정도인지 파악이 필요하다."],"metadata":{"id":"tpoAKSd5djzr"}},{"cell_type":"code","source":["model_name = \"gogamza/kobart-base-v2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KgOtL1_c7bx","outputId":"199c9a04-d8bf-4316-9b65-f13d8b904088","executionInfo":{"status":"ok","timestamp":1678864465900,"user_tz":-540,"elapsed":3512,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]}]},{"cell_type":"code","source":["lengths = []\n","\n","for column in df.columns:\n","  out = tokenizer(df[column][df[column].notna()].tolist())\n","  out = [len(x) for x in out['input_ids']]\n","  lengths.extend(out)\n","\n","lengths = pd.Series(lengths)\n","display(lengths.describe())\n","lengths.plot.hist(bins=80)"],"metadata":{"id":"_CBVAQRwd17o","colab":{"base_uri":"https://localhost:8080/","height":447},"outputId":"7efbd86c-a013-4a17-8169-73ab8fd253a5","executionInfo":{"status":"ok","timestamp":1678864472447,"user_tz":-540,"elapsed":6555,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["count    36793.000000\n","mean        13.147582\n","std          6.909344\n","min          1.000000\n","25%          8.000000\n","50%         12.000000\n","75%         17.000000\n","max        318.000000\n","dtype: float64"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<AxesSubplot:ylabel='Frequency'>"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["정말 긴 문장도 있지만 대부분 토큰 길이가 50아래인 것을 볼 수 있다."],"metadata":{"id":"BVMbeKKqblfw"}},{"cell_type":"markdown","source":["# Dataset class 만들기"],"metadata":{"id":"mKAG52GcfNco"}},{"cell_type":"code","source":["style_map = {\n","    'formal': '문어체',\n","    'informal': '구어체',\n","    'android': '안드로이드',\n","    'azae': '아재',\n","    'chat': '채팅',\n","    'choding': '초등학생',\n","    'emoticon': '이모티콘',\n","    'enfp': 'enfp',\n","    'gentle': '신사',\n","    'halbae': '할아버지',\n","    'halmae': '할머니',\n","    'joongding': '중학생',\n","    'king': '왕',\n","    'naruto': '나루토',\n","    'seonbi': '선비',\n","    'sosim': '소심한',\n","    'translator': '번역기'\n","}"],"metadata":{"id":"n79ijdQDmDq1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["학습에 필요한 Dataset을 만든다, 여러 스타일을 가진 한 문장을 가져온 뒤, 두가지 스타일을 임의로 추출해서 하나를 원본 문장으로 지정하고 encoder의 입력으로 사용하고, 다른 하나를 목표 문장으로 decoder의 입력으로 사용한다."],"metadata":{"id":"5CG29ZWYb2fb"}},{"cell_type":"code","source":["\n","class TextStyleTransferDataset(Dataset):\n","  def __init__(self, \n","               df: pd.DataFrame, \n","               tokenizer: Tokenizer\n","               ):\n","    self.df = df\n","    self.tokenizer = tokenizer\n","    \n","  def __len__(self):\n","    return len(self.df)\n","\n","  def __getitem__(self, index):\n","    row = self.df.iloc[index, :].dropna().sample(2)\n","    text1 = row[0]\n","    text2 = row[1]\n","    target_style = row.index[1]\n","    target_style_name = style_map[target_style]\n","\n","    encoder_text = f\"{target_style_name} 말투로 변환:{text1}\"\n","    decoder_text = f\"{text2}{self.tokenizer.eos_token}\"\n","    model_inputs = self.tokenizer(encoder_text, max_length=64, truncation=True)\n","\n","    with self.tokenizer.as_target_tokenizer():\n","      labels = tokenizer(decoder_text, max_length=64, truncation=True)\n","    model_inputs['labels'] = labels['input_ids']\n","    del model_inputs['token_type_ids']\n","\n","    return model_inputs"],"metadata":{"id":"B4BFEGMWfGsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = TextStyleTransferDataset(df, tokenizer)\n","out = dataset[0]\n","print(out['input_ids'])\n","print(out['labels'])\n","print(tokenizer.decode(out['input_ids']))\n","print(tokenizer.decode(out['labels']))\n","\n","out = dataset[1]\n","print(out['input_ids'])\n","print(out['labels'])\n","print(tokenizer.decode(out['input_ids']))\n","print(tokenizer.decode(out['labels']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjlMq4v-fj02","outputId":"1470d35a-05a5-4c03-b3dd-b24d0570bf98","executionInfo":{"status":"ok","timestamp":1678864353647,"user_tz":-540,"elapsed":9,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[14041, 12080, 14070, 13282, 10338, 14296, 13716, 257, 11699, 9592, 14476, 14784, 17849, 12034, 14195, 26832, 18712, 1700, 214]\n","[14360, 9102, 27616, 11478, 14495, 325, 14651, 16486, 17849, 12034, 14195, 26832, 14947, 16932, 14082, 14959, 11802, 1]\n","아재 말투로 변환:안녕... 난 고양이 6마리 키워 ㅠㅠ\n","아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여</s>\n","[24465, 14070, 13282, 10338, 14296, 13716, 257, 253, 26832, 262, 14364, 10769, 11696, 9735, 9531, 14105, 14452, 9995, 262]\n","[17849, 12034, 245, 14195, 26832, 245, 26746, 245, 14415, 9031, 14514, 8981, 245, 1]\n","안드로이드 말투로 변환:6마리? 에바아니냐 안 힘듦?\n","고양이. 6마리. 양육. 번거로운가.</s>\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# 학습을 위해 train, test set으로 나눈다.\n","df_train, df_test = train_test_split(df, test_size=0.1, random_state=42)\n","print(len(df_train), len(df_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4qxckgQirQn","outputId":"616d428e-422d-46c4-fdf4-d2573b2001c4","executionInfo":{"status":"ok","timestamp":1678864353647,"user_tz":-540,"elapsed":8,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3123 347\n"]}]},{"cell_type":"code","source":["train_dataset = TextStyleTransferDataset(\n","    df_train,\n","    tokenizer\n",")\n","test_dataset = TextStyleTransferDataset(\n","    df_test,\n","    tokenizer\n",")\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer=tokenizer, model=model\n",")"],"metadata":{"id":"cwFher6HigJh","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["c4cd63a4c6c645e5809fb9d305fa83e1","d7dfdacd8ec74f09adcfa82f453505ca","5f530b063bc541f3a2400df68ec75c7b","d49f0d636d454181aa53c0ec17285ed9","8ce6d2640d4f42eb80a0b23de6d53d79","eced711706f04e90a4a3a3e232f21df5","1fe429f6435f4032a9d0a0bab695f700","deb5c7e2f2524d1cb65ff0520a5b608d","dca8ae4807834948989779f96a489604","ec64182d680a44c7bf3c9fb260b6d702","7622aee221ac4d14aa56589cdb87e097"]},"outputId":"d10683d3-664c-44b2-95e9-09925b3ab197","executionInfo":{"status":"ok","timestamp":1678864382201,"user_tz":-540,"elapsed":28560,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4cd63a4c6c645e5809fb9d305fa83e1"}},"metadata":{}}]},{"cell_type":"code","source":["# 조기 학습 종료 \n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# 조기학습종료 발동 조건, 유지 조건(patience, 2회더 체크후 변동없으면 종료)\n","earlyStopping = EarlyStopping( monitor  = 'val_accuracy', \n","                              min_delta = 0.001, \n","                              patience  = 2\n",")"],"metadata":{"id":"RVFntBxe3G-B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 학습 시도 1"],"metadata":{"id":"6XSPT21LOeWf"}},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=24, # number of training epochs\n","    per_device_train_batch_size=16, # batch size for training\n","    per_device_eval_batch_size=16,  # batch size for evaluation\n","    eval_steps=500, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved \n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678862745512,"user_tz":-540,"elapsed":424,"user":{"displayName":"홍성민","userId":"05817123982101120475"}},"outputId":"d9819b52-25a0-4ec4-cead-f1f11cf15e48","id":"Vazsbc0hNH3z"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d81c23fa-69a4-4cd5-bb14-cfcac6b8c1b7","executionInfo":{"status":"ok","timestamp":1678863237157,"user_tz":-540,"elapsed":487542,"user":{"displayName":"홍성민","userId":"05817123982101120475"}},"id":"PU9wNvE2NH30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 3123\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 10\n","  Total train batch size (w. parallel, distributed & accumulation) = 10\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3130\n","  Number of trainable parameters = 123859968\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3130' max='3130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3130/3130 08:03, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.836600</td>\n","      <td>1.848599</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.714800</td>\n","      <td>1.670102</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.502700</td>\n","      <td>1.626384</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.370200</td>\n","      <td>1.543882</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.277100</td>\n","      <td>1.494081</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.221600</td>\n","      <td>1.559854</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 10\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 10\n","Saving model checkpoint to /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000/config.json\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000/generation_config.json\n","Model weights saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 10\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 10\n","Saving model checkpoint to /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000/config.json\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000/generation_config.json\n","Model weights saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000/pytorch_model.bin\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 10\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 10\n","Saving model checkpoint to /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000/config.json\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000/generation_config.json\n","Model weights saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000/pytorch_model.bin\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3130, training_loss=1.6328017895975813, metrics={'train_runtime': 487.2047, 'train_samples_per_second': 64.1, 'train_steps_per_second': 6.424, 'total_flos': 603090688112640.0, 'train_loss': 1.6328017895975813, 'epoch': 10.0})"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["- 학습 시도 2"],"metadata":{"id":"KKzzo4gUOhWJ"}},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=24, # number of training epochs\n","    per_device_train_batch_size=16, # batch size for training\n","    per_device_eval_batch_size=16,  # batch size for evaluation\n","    eval_steps=500, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved \n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")"],"metadata":{"id":"M-jdWyJMmHoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2M4qTRmQmgBq","outputId":"92eb8ce7-941c-45ec-ee2e-c53cae7dc3e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 3123\n","  Num Epochs = 24\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4704\n","  Number of trainable parameters = 123859968\n","You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4704' max='4704' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4704/4704 15:13, Epoch 24/24]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.677100</td>\n","      <td>1.794659</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.607700</td>\n","      <td>1.681948</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.362100</td>\n","      <td>1.478000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.246800</td>\n","      <td>1.622281</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.131900</td>\n","      <td>1.452344</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.053900</td>\n","      <td>1.481652</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.997100</td>\n","      <td>1.540463</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.961400</td>\n","      <td>1.392110</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.914100</td>\n","      <td>1.599943</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000/config.json\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000/generation_config.json\n","Model weights saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000/config.json\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000/generation_config.json\n","Model weights saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000/pytorch_model.bin\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000/config.json\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000/generation_config.json\n","Model weights saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000/pytorch_model.bin\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-4000\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-4000/config.json\n","Configuration saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-4000/generation_config.json\n","Model weights saved in /content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-4000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000] due to args.save_total_limit\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","***** Running Evaluation *****\n","  Num examples = 347\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=4704, training_loss=1.3089464505513508, metrics={'train_runtime': 916.6341, 'train_samples_per_second': 81.769, 'train_steps_per_second': 5.132, 'total_flos': 1551738795909120.0, 'train_loss': 1.3089464505513508, 'epoch': 24.0})"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["trainer.save_model(\"/content/drive/MyDrive/data1/text-transfer-smilegate-bart-eos/\")"],"metadata":{"id":"XneMSSEFmiDG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pipeline을 이용해서 학습한 모델로 텍스트 생성해보기"],"metadata":{"id":"xrYpm7IDmsA7"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","nlg_pipeline = pipeline('text2text-generation',model=model_path, tokenizer=model_name)"],"metadata":{"id":"NSCtZp1Rmr0U","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8639cdf8-441b-4d7d-e1be-404340b861b1","executionInfo":{"status":"ok","timestamp":1678864556331,"user_tz":-540,"elapsed":14692,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-r00-MHH0A_","executionInfo":{"status":"ok","timestamp":1678864529732,"user_tz":-540,"elapsed":27542,"user":{"displayName":"홍성민","userId":"05817123982101120475"}},"outputId":"02d9ad87-4cc2-4361-f6b1-f5da64860915"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["def generate_text(pipe, text, target_style, num_return_sequences=5, max_length=60):\n","  target_style_name = style_map[target_style]\n","  text = f\"{target_style_name} 말투로 변환:{text}\"\n","  out = pipe(text, num_return_sequences=num_return_sequences, max_length=max_length)\n","  return [x['generated_text'] for x in out]"],"metadata":{"id":"F2yThRHfmw1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_styles = df.columns\n","src_text = \"\"\"\n","오늘 정기 발령이 났거든. 그런데 우리 집에서 두 시간 넘게 떨어진 곳으로 발령이 났어. 이거 어떻게 출퇴근하라는 것인지 모르겠다.\n","\"\"\"\n","\n","print(\"입력 문장:\", src_text)\n","for style in target_styles:\n","  print(style, generate_text(nlg_pipeline, src_text, style, num_return_sequences=1, max_length=1000)[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c19xmx3Xn6Fq","outputId":"aeb39961-b9a0-48b6-cba9-c7e233c19b8b","executionInfo":{"status":"ok","timestamp":1678867177635,"user_tz":-540,"elapsed":24660,"user":{"displayName":"홍성민","userId":"05817123982101120475"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 문장: \n","오늘 정기 발령이 났거든. 그런데 우리 집에서 두 시간 넘게 떨어진 곳으로 발령이 났어. 이거 어떻게 출퇴근하라는 것인지 모르겠다.\n","\n","formal 오늘 아침에 발령이 났어요. 그런데 집에서 두시간 정도 떨어져 있는 곳으로 발령이 났어요. 어떻게 출퇴근을 하라는 것인지 모르겠어요.\n","informal 오늘 아침에 발령이 났는데, 우리 집에서 두시간 정도 떨어져 있는 곳으로 발령이 났어. 어떻게 출퇴근을 하라는 말야?\n","android 오늘. 발령. 그러나. 우리집. 두시간. 거리. 이동. 목적지. 어디인가.\n","azae 오늘 아침에 발령이 났는데, 우리 집에서 두시간 정도 떨어져 있는 곳에서 발령이 났어~ 어떻게 출퇴근을 하라는 거여?\n","chat 오늘 아침에 발령났는데 집에서 두시간 정도 떨어져 있는 곳에서 발령났어.. 어떻게 출퇴근하는 거임?\n","choding 오늘 아침에 발령 났는데 집에서 두 시간 정도 떨어져 있는 곳에서 발령났어 이거 어떻게 출퇴근을 함?\n","emoticon 오늘 아침에 발령이 났는데, 집에서 두시간 정도 떨어져 있는 곳에서 발령이 났어! 어떻게 출퇴근을 하라는 거야? (⊙_⊙)?\n","enfp 오늘 기 발령이 났엉!! 근데 우리 집에서 두 시간 이상 떨어져 있는 곳에서 발령이 났엉!! 어떻게 출퇴근을 하라는 거얌?!\n","gentle 오늘 아침에 발령이 났습니다. 그런데 집에서 두시간 정도 떨어져 있는 곳으로 발령이 났습니다. 어떻게 출퇴근을 하라는 말입니까?\n","halbae 오늘... 발령이 났구먼...그런디...우리 집에서 두시간 정도 떨어져 있는 곳에 발령이 났구먼...어떻게 출퇴근을 하라는 말인겐가?...\n","halmae 오늘 기 발령났는디, 우리 집에서 두 시간이나 떨어져 있는 곳에서 발령났어 이거 어떻게 출퇴근을 시킨다는 거여?\n","joongding 오늘 아침에 발령날라는데 집에서 두시간 거리에서 출퇴근하는건데 뭔소리\n","king 오늘 기 발령이 났소. 허나 짐의 집에서 두시간 정도 떨어져 있는 곳에 발령이 났소. 어찌 출퇴근을 하라는 말인가?\n","naruto 오늘 아침에 발령이 났다니깐! 근데 집에서 두시간 정도 떨어져 있는 곳에 발령이 났다니깐! 어떻게 출퇴근을 한다는 거냐니깐!\n","seonbi 오늘 아침에 발령이 났소! 그런데 집에서 두시간 정도 떨어져 있는 곳에 발령이 났소! 어떻게 출퇴근을 하라는 것이오?\n","sosim 오늘 아침에 발령났어.. 근데 우리집에서 두시간 거리에서 출퇴근하는건지 모르겠어..\n","translator 오늘 나는 발령이 났다, 그러나 나는 집에서 두시간 정도 떨어져 있는 곳에 발령을 받았다. 당신은 어떻게 출퇴근을 계획?\n"]}]},{"cell_type":"markdown","source":["[참고](https://heegyukim.medium.com/korean-smilestyle-dataset%EC%9C%BC%EB%A1%9C-%EB%AC%B8%EC%B2%B4-%EC%8A%A4%ED%83%80%EC%9D%BC%EC%9D%84-%EB%B0%94%EA%BE%B8%EB%8A%94-%EB%AA%A8%EB%8D%B8-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B4%EA%B8%B0-d15d32a2c303)"],"metadata":{"id":"o7gDvbkQU23a"}}]}